%\patxi{[[[Publication Title: "test"] OR [Publication Title: "testable"]] AND [[Publication Title: "commit"] OR [Publication Title: "snapshot"] OR [Publication Title: "history"] ]] OR [[[Abstract: "test"] OR [Abstract: "testable"]] AND [[Abstract: "commit"] OR [Abstract: "snapshot"] OR [Abstract: "history"]]]}

Compilability of software projects is fundamental to be able to execute tests. %Following are the works that address this property of the projects:
Studying the compilability of past snapshots has been a topic of several publications, however, to the author's awareness, there are no studies of the testability of past snapshots. 
% Among the works on compilability, Tufano et al.~\cite{tufano2017there} is one of the most recent studies on the topic. 
% They analyzed 100 Java Apache projects, trying to build all the commits of each project. 
% They concluded that the compilability degraded over time, being the oldest commits the ones that more commonly failed to build. 
% Their work also included a categorization of the build failures, with missing dependencies ranking first among the different reasons collected. 
% This work has been validated~\cite{sulir2020large} and extended~\cite{maes2022revisiting} by other authors, confirming the degradation of compilability over time.

% Rausch et al.~\cite{Rausch:2017:EAB:3104188.3104231} specifically addressed the reasons why builds fail in the context of CI environments. 
% They analyzed Travis logs from 14 open-source projects, finding that a significant fraction of errors corresponded to tests that failed because of a failure in a previous build. 
% The study analyzed the build logs from the point of view of continuous integration systems (snapshot build and test execution), but it did not include a reproduction of the builds. 
% Furthermore, due to the nature of CI systems, where data is removed after some time, not all past snapshots of the analyzed projects were considered. 
%Similarly, in~\cite{gallaba2018noise}, the authors analyze
% Noise and heterogeneity in historical build data: an empirical study of Travis CI\cite{gallaba2018noise}

% The study of past snapshots to detect bug-introducing commits is tackled by Querel et al.~\cite{querel:2021:warning}. 
% The authors partially replicate the work by Tufano et al., by trying to improve the compilability of eight of the Maven-based projects. 
% They do so by solving the \textit{missing dependency} problem, selecting a dependency close to the commit date. 
% Through this technique a compilability of 78.4\% is reported -- doubling in compilability compared to prior work. For those commits whose build fail, they run the \texttt{findbugs} tool~\cite{ayewah2007using} in an attempt to understand if the failure could be caused by a bug. 
% Their results were negative, although developers found the reports offered by \texttt{findbugs} useful.

% Build breakage repair techniques have been also proposed. Macho et al. derived three automatic repair techniques from 37 broken Maven builds~\cite{macho2018automatically}. 
% Using these techniques, they were able to automatically fix 45 of an additional 84 broken builds. 
% Similarly, Lou et al. focused on repairing build failures with the \texttt{HireBuild} tool~\cite{lou:2019:historyfailurefix}. 
% \texttt{HireBuild} analyzes the history of the project and other external sources, and automatically proposes build fixing techniques to repair broken builds. 

% Trautsch et al. studied the history of commits of 54 projects, reporting the trends in warnings raised by the automated static analysis tool called \texttt{PMD}~\cite{trautsch2020longitudinal}. They found that large changes in ASAT (Automated Static Analysis Tools) warnings are due to changes in the coding style. They also proved that the presence of \texttt{PMD} has no influence in removing warnings, although it does in defect density.

% Other authors used a different strategy to achieve higher compilability. Behnamghader et al. focus solely on a module within the software (the one that changes)~\cite{behnamghader2018scalable}. They achieved high compilability for the three different datasets considered (Apache, Google and Netflix), above 94\% in all cases. Surprisingly, another work by He et al. has found that the presence of broken builds did not result in an increase of commit frequency (thus working on solving the breakage)~\cite{he2020characteristics}. The authors also reported a correlation between tags like \textit{feature add} or \textit{refactoring} linked to a broken build, after studying 68 Java repositories.

Beller et al. offer insight into the testing practices that are common in CI-based software development, finding that testing is the single most important reason why builds fail~\cite{beller2017oops}.

Pecorelli et al. chose eight Apache projects to study the relation of test-related factors on software quality, based on the compilability information provided by Tufano et al.~\cite{tufano2017there} for these projects. On these projects, they performed several analyses to determine the quality of the tests and their impact in production failures. Some of the test-related factors considered required the execution of the tests; therefore the authors carefully selected projects with high compilability. However, they did not run all the commits in the history -- just those commits which were connected with a failure in a product release. 

Garousi et al. performed a survey on \textit{testability}~\cite{garousi2019survey}, finding several uses of this term in the research literature. All of these uses do not consider testability of past snapshots. In this regard, the way we refer to \textit{testability} in this thesis could be understood as \textit{project history testability}.

% The Defects4J~\cite{just2014defects4j} dataset is a collection of Java projects where the regressions in the code are well documented. They offer a reproducible scenario where you can check the correct behavior (or not) of the tests in different commits of the project history. This scenario has been provided by the authors themselves, encapsulating the project dependencies together with the source code, as well as having all the necessary tools for the execution of the tests in the form of binaries (and in their most recent versions, using Docker to isolate the execution). Although they run the tests on past commits, they do not run them on their entire history to check their testability.

%\patxi{Analizan los tests en CI: Oops, my tests broke the build: An explorative analysis of travis ci with github}
