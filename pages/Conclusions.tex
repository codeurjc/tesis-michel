This chapter recapitulates the initial objectives of the research and the contributions claimed in Chapter~\ref{chapter:intro}, in addition to presenting the conclusions (Section~\ref{sec:conclusions}) of the three studies included in this PhD. thesis. 
In addition, Section~\ref{sec:future-work} also details future research work.

\section{Conclusions}
\label{sec:conclusions}

\subsection{Revisiting the building of past snapshots}

In Chapter~\ref{chapter:buildability} we have shown a replication and a reproduction study from Tufano et al. work~\cite{tufano2017there} about the compilability of the history of past commits of a project. 
In the first one we have repeated their analysis, with those repositories for which we found all commits, and in the second one we extended its generality by using the same methodology with a different, more diverse set of Java projects, and considering also Ant and Gradle in addition to Maven.

The main contributions of this chapter are:

\begin{itemize}
\item A discussion and guidelines on reproduction packages for studies on the compilability of past snapshots. 
\item A dataset and software, usable by other researchers, to study long-term degradation of compilability.
\item A partial validation of the results of the original study. In particular, results about frequency of errors causing build failures have been validated and extended.
\item Evidence on how compilability degrades over time, and how it could be mitigated by ensuring future availability of dependencies.
\item Evidence on the compilability of a different, more diverse set of Java projects, showing some differences with the original study.
\item Evidence on how the building tools affect future compilability.
\end{itemize}

%\grex{Lo he dejado así}
%:\jgb{Lo he retocado un poco}
In summary, we wanted to shed some more light on to which extent past snapshots of projects are compilable ``as such'', because that is the basis to know how much build-repair techniques are needed if past artifacts of a project need to be reproduced from source code.
Since our study was a replication and a reproduction, a part of our results could be expected, but still they add more detail and evidence to the original study. In addition, we also found some differences, generalized evidence by analyzing a more diverse set of projects, and produced a tool to automate the analysis of any Java repository, which could be used in further studies by any researcher.

\subsection{Testing the past: can we still run tests in past snapshots?}

In Chapter~\ref{chapter:testability} we have started a path to analyze to which extent past snapshots of a project can be tested. 
For that, we have conducted an empirical analysis of many Java projects from a well-known dataset. 
We also propose a framework for conducting further analysis, based on the different steps needed to successfully run tests for each snapshot. 
Using this framework, we have found that for more than half the snapshots, all tests cannot be run successfully.
However, the main result is the high variability of testability from project to project, even within relatively homogeneous dataset. 
% In this respect, we also discard some hypothesis on the influence of characteristics of projects (lines of code, number of commits, age) in testability.

%In this paper we offer a study of the testability of the history of 111 Java projects, which extends previous studies on the buildability of project history. 
%We also provide a complete study that discards some of the most common metrics of a project (lines of code, number of commits or its age) as factors that determine its testability. 
%We have found that in most projects it is not possible to reproduce the tests in the past.
%In addition, we conducted a preliminary study of the causes that can lead to low testability in Java projects.
%Analysing the projects we have found great variability, even among projects selected under the same criteria. 

We note that many projects cannot rely on running tests in past commits, as these won’t run or even compile.
Testing snapshots of the past is fundamental for the maintainability of old versions of the project which are still in production. 
Therefore, we expect more research in this area in the future. 
Fortunately, we have found some signals showing that good practices can be identified to increment testability of current snapshots (that will become past snapshots with time). 
We have also suggested some ways of increasing testability of past snapshots improving the methods we are using for building and running tests in them. 
Of course, extending our study to other samples of Java code, and to other programming languages, will improve our knowledge in this area.

%and also that some techniques could be used to of those snapshots, 
%Replication testing is essential to improve the maintainability of projects that need to be maintained in previous versions.
%Reproducing this study using other languages such as Python, Javascript or C++ could lead to interesting future work.

\subsection{Identifying which change caused a bug through regression testing}

In Chapter~\ref{chapter:bug-hunter} \patxi{we leverage the knowledge and tools researched in chapters 3 and 4 to operationalize...}we operationalize the theoretical method, called \emph{perfect test}, to detect the change that introduced a bug (BIC), by using a regression test as perfect test. We show, using a well-known bugs dataset~\cite{just2014defects4j}, that the method works for those bugs where we are able to transplant the regression test in the past and find a commit where this test passes again, by using our tool to automatically detect the BIC and then validating the results. 

However, we also find that our method is limited by the transplantability of regression tests to past snapshots, and in particular by the compilability of past snapshots.

As a result of applying our method, we produce, by a completely automated procedure, a dataset of BICs (\datasetName), that can be used as ground truth for evaluating methods for detecting BICs. 
We apply it to some SZZ derivatives, proposing a method for evaluating their relative performance, and verifying a well-known limitation of them. 
This method could be exploited for producing, automatically, much larger collections of BICs. 
We also propose our method for automatically providing developers fixing a bug with detailed information about the BIC that introduced it.

\section{Future Work}
\label{sec:future-work}

The studies presented in this doctoral thesis are limited to projects written in the Java programming language. Moreover, these projects are mostly programming libraries, which usually have only unit tests and sometimes integration tests.
Therefore, further research is still needed to draw general conclusions on the compilability of past snapshots, testability of the past snapshots and to identify the change that introduced the bug, especially for languages other than Java (C, C++, Python, JavaScript, Go, Rust and other popular programming languages), and in general to projects with different testing practices (e.g., including load testing or end-to-end testing).

In Chapter~\ref{chapter:testability}, one of the main limitations we have encountered when running the tests is to reproduce in context the test execution. Despite having the tests collected in the commit history, we do not have the information of whether these tests could be compiled and subsequently executed, as well as the absence of the result of the execution. 
This information could be obtained from the Continuous Integration (CI) system (if used), where the build of projects and the execution of their tests is done automatically, and their results are recorded.
It has been a very common practice for open-source projects to use continuous integration systems that are not publicly accessible (such as Jenkins) and therefore it is not possible to retrieve test construction and execution information. 
Even so, numerous projects have used Travis~\footnote{\url{https://www.travis-ci.com/}} as a continuous integration system. This CI system has allowed projects such as TravisTorrent~\cite{msr17challenge} to offer build and test execution datasets for over 1,000 projects. 
Within the open-source world, this CI system is gradually being replaced by GitHub Actions, another CI system integrated into the GitHub platform (the most widely used Git repository platform). 
Therefore, a possible future work would be to create a new dataset of builds and test executions to help us understand how the tests behaved at the time they were executed and in the right context. 
This future work would have to deal with problems such as the fact that such executions (together with their results and logs) usually have a maximum lifetime of 90 days, so we would have to "record" such executions over a period of time.

In Chapter~\ref{chapter:bug-hunter}, we propose a tool that exhaustively searches for the change that introduced an error. 
However, this tool is limited by the problems in reproducing the test context and the time required to compute the regression test run results in the change history.
It would be interesting to continue the proposed work by trying to combine our tool with the most recent implementations of SZZ. 
Our tool would refine and extend the candidates proposed by this algorithm, while the SZZ algorithm could sensibly reduce the execution time of our tool by filtering out irrelevant changes.

% The replication and reproduction study in Chapter~\ref{chapter:buildability} continues the work of Tufano et al.~\cite{tufano2017there}, validating and extending its conclusions. 
% However, both studies and remain very limited to the Java programming language, but also to projects that are basically programming libraries. 
% Future lines of work can extend this study by exploring the application of the method on datasets of projects in other programming languages than Java (Python, C, C++ ...), of other types of projects (not only libraries), and in general to projects with different testing practices.