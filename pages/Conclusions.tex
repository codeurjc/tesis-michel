This chapter recapitulates the initial objectives of the research and the contributions claimed in Chapter 1, in addition to presenting the conclusions (Section~\ref{sec:conclusions}) of the three studies included in this doctoral thesis. 
In addition, Section~\ref{sec:future-work} also details future research work.

\section{Conclusions}
\label{sec:conclusions}

\subsection{Revisiting the building of past snapshots}

In Chapter~\ref{chapter:buildability} we have shown a replication and a reproduction study from Tufano et al. work~\cite{tufano2017there} about the compilability of the history of past commits of a project. 
In the first one we have repeated their analysis, with those repositories for which we found all commits, and in the second one we extended its generality by using the same methodology with a different, more diverse set of Java projects, and considering also Ant and Gradle in addition to Maven.

The main contributions of this chapter are:

\begin{itemize}
\item A discussion and guidelines on reproduction packages for studies on the compilability of past snapshots. 
\item A dataset and software, usable by other researchers, to study long-term degradation of compilability.
\item A partial validation of the results of the original study. In particular, results about frequency of errors causing build failures have been validated and extended.
\item Evidence on how compilability degrades over time, and how it could be mitigated by ensuring future availability of dependencies.
\item Evidence on the compilability of a different, more diverse set of Java projects, showing some differences with the original study.
\item Evidence on how the building tools affect future compilability.
\end{itemize}

%\grex{Lo he dejado as√≠}
%:\jgb{Lo he retocado un poco}
In summary, we wanted to shed some more light on to which extent past snapshots of projects are compilable ``as such'', because that is the basis to know how much build-repair techniques are needed if past artifacts of a project need to be reproduced from source code.
Since our study was a replication and a reproduction, a part of our results could be expected, but still they add more detail and evidence to the original study. In addition, we also found some differences, generalized evidence by analyzing a more diverse set of projects, and produced a tool to automate the analysis of any Java repository, which could be used in further studies by any researcher.

\subsection{Chapter 4 conclusions}

In Chapter~\ref{chapter:testability} ... \michel{TODO}

\subsection{Identifying which change caused a bug through regression testing}

In Chapter~\ref{chapter:bug-hunter} we operationalize the theoretical method, called \emph{perfect test}, to detect the change that introduced a bug (BIC), by using a regression test as perfect test. We show, using a well-known bugs dataset~\cite{just2014defects4j}, that the method works for those bugs where we are able to transplant the regression test in the past and find a commit where this test passes again, by using our tool to automatically detect the BIC and then validating the results. 

However, we also find that our method is limited by the transplantability of regression tests to past snapshots, and in particular by the compilability of past snapshots.

As a result of applying our method, we produce, by a completely automated procedure, a dataset of BICs (\datasetName), that can be used as ground truth for evaluating methods for detecting BICs. 
We apply it to some SZZ derivatives, proposing a method for evaluating their relative performance, and verifying a well-known limitation of them. 
This method could be exploited for producing, automatically, much larger collections of BICs. 
We also propose our method for automatically providing developers fixing a bug with detailed information about the BIC that introduced it.

\section{Future Work}
\label{sec:future-work}

The studies presented in this doctoral thesis are limited to projects written in the Java programming language. Moreover, these projects are mostly programming libraries, which usually have only unit tests and sometimes integration tests.
Therefore, further research is still needed to draw general conclusions on the compilability of past snapshots, testability of the past snapshots and to identify the change that introduced the bug, especially for languages other than Java (C, C++, Python, JavaScript, Go, Rust and other popular programming languages), and in general to projects with different testing practices (e.g., including load testing or end-to-end testing).

In Chapter~\ref{chapter:testability}, one of the main limitations we have encountered when running the tests is to reproduce in context the test execution. Despite having the tests collected in the commit history, we do not have the information of whether these tests could be compiled and subsequently executed, as well as the absence of the result of the execution. 
This information could be obtained from the Continuous Integration (CI) system (if used), where the build of projects and the execution of their tests is done automatically, and their results are recorded.
It has been a very common practice for open-source projects to use continuous integration systems that are not publicly accessible (such as Jenkins) and therefore it is not possible to retrieve test construction and execution information. 
Even so, numerous projects have used Travis~\footnote{\url{https://www.travis-ci.com/}} as a continuous integration system. This CI system has allowed projects such as TravisTorrent~\cite{msr17challenge} to offer build and test execution datasets for over 1,000 projects. 
Within the open-source world, this CI system is gradually being replaced by GitHub Actions, another CI system integrated into the GitHub platform (the most widely used Git repository platform). 
Therefore, a possible future work would be to create a new dataset of builds and test executions to help us understand how the tests behaved at the time they were executed and in the right context. 
This future work would have to deal with problems such as the fact that such executions (together with their results and logs) usually have a maximum lifetime of 90 days, so we would have to "record" such executions over a period of time.

In Chapter~\ref{chapter:bug-hunter}, we propose a tool that exhaustively searches for the change that introduced an error. 
However, this tool is limited by the problems in reproducing the test context and the time required to compute the regression test run results in the change history.
It would be interesting to continue the proposed work by trying to combine our tool with the most recent implementations of SZZ. 
Our tool would refine and extend the candidates proposed by this algorithm, while the SZZ algorithm could sensibly reduce the execution time of our tool by filtering out irrelevant changes.

% The replication and reproduction study in Chapter~\ref{chapter:buildability} continues the work of Tufano et al.~\cite{tufano2017there}, validating and extending its conclusions. 
% However, both studies and remain very limited to the Java programming language, but also to projects that are basically programming libraries. 
% Future lines of work can extend this study by exploring the application of the method on datasets of projects in other programming languages than Java (Python, C, C++ ...), of other types of projects (not only libraries), and in general to projects with different testing practices.